Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,-0.24797845,999.0,-5.123333712418874,-5.123333712418874,1.0
20000,1.4189383,-0.26931566,999.0,-5.140000408887863,-5.140000408887863,1.0
30000,1.4172791,-0.25006124,947.9,-4.3280911879106005,-4.3280911879106005,1.0
40000,1.4171644,-0.2519226,927.8181818181819,-3.7333638776432383,-3.7333638776432383,1.0
50000,1.417179,-0.13190453,796.3846153846154,-2.233166848619779,-2.233166848619779,1.0
60000,1.4171808,-0.10421231,717.4615384615385,-1.9164287618228368,-1.9164287618228368,1.0
70000,1.4152187,0.02311429,922.2727272727273,-4.172545768997886,-4.172545768997886,1.0
80000,1.4148127,0.07362445,999.0,-5.00100029706955,-5.00100029706955,1.0
90000,1.413553,0.051149398,866.5833333333334,-3.5195835878451667,-3.5195835878451667,1.0
100000,1.4131964,0.013775315,860.0,-3.4038184068419715,-3.4038184068419715,1.0
110000,1.4111981,0.005616759,862.25,-3.609750285744667,-3.609750285744667,1.0
120000,1.4104475,-0.003977745,779.0,-2.744666968782743,-2.744666968782743,1.0
130000,1.4093013,-0.0015227247,557.6842105263158,-0.2938423439076072,-0.2938423439076072,1.0
140000,1.4087468,0.01896941,660.0,-1.4932002902030945,-1.4932002902030945,1.0
150000,1.4060674,-0.05538598,675.5,-1.7624288243906838,-1.7624288243906838,1.0
160000,1.4044698,0.0402592,738.3571428571429,-2.475571734564645,-2.475571734564645,1.0
170000,1.4013506,-0.041912336,792.4615384615385,-3.112923461657304,-3.112923461657304,1.0
180000,1.3990535,-0.0074812584,722.8461538461538,-2.437923403886648,-2.437923403886648,1.0
